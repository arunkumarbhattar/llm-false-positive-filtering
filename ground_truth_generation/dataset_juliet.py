#!/usr/bin/env python3
"""
dataset_juliet.py

This script processes CodeQL-generated SARIF files, maps findings to their respective
functions in the Juliet Test Suite, labels them based on ground truth information,
and builds a dataset for evaluation purposes.

Usage:
    python dataset_juliet.py --sarif cpp.sarif --tags-file tags.txt --output dataset.json
"""

import json
import re
import argparse
import os
import logging
from enum import Enum

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')


class GroundTruth(Enum):
    GOOD = "GOOD"         # False Positive
    BAD = "BAD"           # True Positive
    UNRELATED = "UNRELATED"  # Not Applicable


def parse_arguments():
    """
    Parses command-line arguments.

    Returns:
        argparse.Namespace: Parsed command-line arguments.
    """
    parser = argparse.ArgumentParser(
        description="Process CodeQL SARIF files, map findings to functions, label them, and build a dataset."
    )
    parser.add_argument(
        '--sarif',
        required=True,
        help="Path to the input CodeQL SARIF file (e.g., cpp.sarif)."
    )
    parser.add_argument(
        '--tags-file',
        required=True,
        help="Path to the tags file generated by ctags (e.g., tags.txt)."
    )
    parser.add_argument(
        '--output',
        required=True,
        help="Path to the output dataset file (e.g., dataset.json)."
    )
    parser.add_argument(
        '--base-dir',
        default='.',
        help="Base directory for resolving relative paths (default: current directory)."
    )
    return parser.parse_args()


def full_path(base_dir, rel_path):
    """
    Constructs the absolute path by joining the base directory with a relative path.

    Args:
        base_dir (str): The base directory path.
        rel_path (str): The relative path.

    Returns:
        str: The combined absolute path.
    """
    return os.path.join(base_dir, rel_path)


def parse_tagfile(tags_path):
    """
    Parses the tags file to map filenames to their functions and corresponding line ranges.

    Args:
        tags_path (str): Path to the tags file.

    Returns:
        dict: A dictionary mapping filenames to lists of (function_name, start_line, end_line).
    """
    tags = {}
    try:
        with open(tags_path, 'r') as file:
            for line in file:
                line = line.strip()
                if not line or line.startswith('!'):
                    continue  # Skip empty lines and metadata

                parts = line.split('\t')
                if len(parts) < 3:
                    logging.warning(f"Malformed tags line: {line}")
                    continue

                funcname, filename, details = parts[:3]

                # Extract start and end lines using regex
                start_match = re.search(r'line:(\d+)', details)
                end_match = re.search(r'end:(\d+)', details)

                if start_match:
                    startline = int(start_match.group(1))
                else:
                    logging.warning(f"Start line not found in line: {line}")
                    startline = 0

                if end_match:
                    endline = int(end_match.group(1))
                else:
                    # If end line isn't provided, assume function is a single line
                    endline = startline

                tags.setdefault(filename, []).append((funcname, startline, endline))
    except FileNotFoundError:
        logging.error(f"Tags file not found: {tags_path}")
    except Exception as e:
        logging.error(f"Error parsing tags file {tags_path}: {e}")

    logging.info(f"Parsed tags for {len(tags)} files.")
    return tags


def is_good(string):
    """
    Checks if the given string indicates a 'good' (non-vulnerable) entity.

    Args:
        string (str): The string to check.

    Returns:
        bool: True if 'good' is in the string, else False.
    """
    return bool(string) and re.search(r'\bgood\b', string, re.IGNORECASE)


def is_bad(string):
    """
    Checks if the given string indicates a 'bad' (vulnerable) entity.

    Args:
        string (str): The string to check.

    Returns:
        bool: True if 'bad' is in the string, else False.
    """
    return bool(string) and re.search(r'\bbad\b', string, re.IGNORECASE)


def get_function_loc(tags, src_filename, lineno):
    """
    Determines which function a specific line number belongs to within a source file.

    Args:
        tags (dict): Parsed tags mapping filenames to functions.
        src_filename (str): The source file name.
        lineno (int): The line number to locate.

    Returns:
        tuple or None: (function_name, start_line, end_line) if found, else None.
    """
    functions = tags.get(src_filename, [])
    matched_funcs = [func for func in functions if func[1] <= lineno <= func[2]]

    if len(matched_funcs) == 1:
        return matched_funcs[0]
    elif len(matched_funcs) > 1:
        logging.warning(f"Multiple functions matched for {src_filename}:{lineno}: {matched_funcs}")
    else:
        logging.warning(f"No function matched for {src_filename}:{lineno}")
    return None


def get_ground_truth(src_filename, func_name):
    """
    Assigns a ground truth label based on the presence of 'good' or 'bad' in filenames or function names.

    Args:
        src_filename (str): The source file name.
        func_name (str): The function name.

    Returns:
        GroundTruth: The ground truth label (GOOD, BAD, or UNRELATED).
    """
    if is_good(src_filename) or is_good(func_name):
        return GroundTruth.GOOD
    if is_bad(src_filename) or is_bad(func_name):
        return GroundTruth.BAD
    return GroundTruth.UNRELATED


def dump_src(base_dir, filename, start, end):
    """
    Extracts source code lines from a file between start and end lines, inclusive.

    Args:
        base_dir (str): Base directory for resolving the filename.
        filename (str): The name of the file to read from.
        start (int): The starting line number (1-based).
        end (int): The ending line number (inclusive, 1-based).

    Returns:
        str: A string containing the file content from start line to end line
             with line numbers prepended.
    """
    path = full_path(base_dir, filename)
    try:
        with open(path, 'r') as file:
            lines = file.readlines()

        # Ensure the line numbers are within the valid range
        start = max(1, start)  # Ensure start is at least 1
        end = min(len(lines), end)  # Ensure end does not exceed the number of lines

        # Slice the list to get lines from start to end (inclusive)
        selected_lines = lines[start-1:end]

        # Prepend line numbers
        numbered_lines = [f"{i + start}: {line}" for i, line in enumerate(selected_lines)]

        return ''.join(numbered_lines)
    except FileNotFoundError:
        logging.error(f"Source file not found: {path}")
        return ""
    except Exception as e:
        logging.error(f"Error reading file {path}: {e}")
        return ""


def parse_codeql_sarif(sarif_path, base_dir, target_rule_id=None):
    """
    Parses the CodeQL SARIF file to extract relevant findings.

    Args:
        sarif_path (str): Path to the SARIF file.
        base_dir (str): Base directory for resolving file paths.
        target_rule_id (str, optional): Specific rule ID to filter findings. Defaults to None.

    Returns:
        list: A list of tuples containing (uri, line_number, message).
    """
    codeql_results = []
    try:
        with open(sarif_path, 'r') as f:
            sarif_data = json.load(f)

        for run in sarif_data.get('runs', []):
            rules_metadata = run.get('tool', {}).get('driver', {}).get('rules', [])
            for result in run.get('results', []):
                rule_id = result.get('ruleId')
                rule_index = result.get('ruleIndex')

                if target_rule_id and rule_id != target_rule_id:
                    continue  # Skip if the rule ID doesn't match

                rule_level = rules_metadata[rule_index].get('defaultConfiguration', {}).get('level', '')
                if rule_level not in ['error', 'warning']:
                    continue  # Skip if the rule level is not 'error' or 'warning'

                msg = result.get('message', {}).get('text', '')
                for location in result.get('locations', []):
                    phys_loc = location.get('physicalLocation', {})
                    artifact = phys_loc.get('artifactLocation', {})
                    uri = artifact.get('uri')
                    lineno = phys_loc.get('region', {}).get('startLine')

                    if uri and lineno:
                        codeql_results.append((uri, lineno, msg))
                    else:
                        logging.warning(f"Missing URI or line number in result: {result}")

        logging.info(f"Parsed {len(codeql_results)} CodeQL results from SARIF.")
    except FileNotFoundError:
        logging.error(f"SARIF file not found: {sarif_path}")
    except json.JSONDecodeError as e:
        logging.error(f"Error parsing SARIF JSON file {sarif_path}: {e}")
    except Exception as e:
        logging.error(f"Unexpected error while parsing SARIF: {e}")

    return codeql_results


def build_dataset(tags, codeql_results, base_dir):
    """
    Builds a dataset by mapping CodeQL findings to functions and labeling them.

    Args:
        tags (dict): Parsed tags mapping filenames to functions.
        codeql_results (list): List of tuples containing (uri, line_number, message).
        base_dir (str): Base directory for resolving file paths.

    Returns:
        list: A list of dictionaries containing dataset entries.
    """
    dataset = []
    for uri, lineno, msg in codeql_results:
        func_loc = get_function_loc(tags, uri, lineno)
        if not func_loc:
            continue  # Skip if function location is ambiguous or not found

        func_name, func_startline, func_endline = func_loc
        gt = get_ground_truth(uri, func_name)
        func_src = dump_src(base_dir, uri, func_startline, func_endline)

        dataset.append({
            'uri': uri,
            'line_number': lineno,
            'message': msg,
            'function_source': func_src,
            'ground_truth': gt.value
        })

    logging.info(f"Built dataset with {len(dataset)} entries.")
    return dataset


def save_dataset(dataset, output_path):
    """
    Saves the dataset to a JSON file.

    Args:
        dataset (list): The dataset to save.
        output_path (str): Path to the output JSON file.
    """
    try:
        with open(output_path, 'w') as f:
            json.dump(dataset, f, indent=2)
        logging.info(f"Dataset saved to {output_path}")
    except Exception as e:
        logging.error(f"Error saving dataset to {output_path}: {e}")


def evaluate_dataset(dataset):
    """
    Evaluates the dataset by counting true positives, false positives, and unrelated findings.

    Args:
        dataset (list): The dataset to evaluate.

    Returns:
        tuple: Counts of (TP, FP, Unrelated).
    """
    cnt_tp = sum(1 for entry in dataset if entry['ground_truth'] == GroundTruth.BAD.value)
    cnt_fp = sum(1 for entry in dataset if entry['ground_truth'] == GroundTruth.GOOD.value)
    cnt_unrelated = sum(1 for entry in dataset if entry['ground_truth'] == GroundTruth.UNRELATED.value)

    return cnt_tp, cnt_fp, cnt_unrelated


def main():
    args = parse_arguments()
    base_dir = os.path.abspath(args.base_dir)

    # Parse the tags file
    tags = parse_tagfile(full_path(base_dir, args.tags_file))

    # Parse CodeQL SARIF results
    codeql_results = parse_codeql_sarif(full_path(base_dir, args.sarif))

    # Build the dataset
    dataset = build_dataset(tags, codeql_results, base_dir)

    # Save the dataset
    save_dataset(dataset, full_path(base_dir, args.output))

    # Evaluate the dataset
    cnt_tp, cnt_fp, cnt_unrelated = evaluate_dataset(dataset)
    logging.info(f"CodeQL Evaluation Results:")
    logging.info(f"True Positives (TP): {cnt_tp}")
    logging.info(f"False Positives (FP): {cnt_fp}")
    logging.info(f"Unrelated Findings: {cnt_unrelated}")

    # Print the counts
    print("codeql #tp, #fp, #unrelated:", cnt_tp, cnt_fp, cnt_unrelated)


if __name__ == '__main__':
    main()
